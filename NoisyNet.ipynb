{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6942,"status":"ok","timestamp":1702584128562,"user":{"displayName":"Alireza Vosoughi Rad","userId":"06911821094483688911"},"user_tz":420},"id":"Uh3JWSU7Tf3h"},"outputs":[],"source":["import math\n","import numpy as np\n","from torch import nn\n","import torch.nn.functional as F\n","import torch\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","from collections import deque\n","import itertools\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1702584128564,"user":{"displayName":"Alireza Vosoughi Rad","userId":"06911821094483688911"},"user_tz":420},"id":"-qVYDpgC2KPY"},"outputs":[],"source":["device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1702584128565,"user":{"displayName":"Alireza Vosoughi Rad","userId":"06911821094483688911"},"user_tz":420},"id":"D87C9OzxUGL7"},"outputs":[],"source":["visited_mark = 0.8  # Cells visited by the rat will be painted by gray 0.8\n","rat_mark = 0.5      # The current rat cell will be painteg by gray 0.5\n","LEFT = 0\n","UP = 1\n","RIGHT = 2\n","DOWN = 3\n","\n","# Actions dictionary\n","actions_dict = {\n","    LEFT: 'left',\n","    UP: 'up',\n","    RIGHT: 'right',\n","    DOWN: 'down',\n","}\n","\n","num_actions = len(actions_dict)\n","\n","# Exploration factor\n","epsilon = 0.1"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":277,"status":"ok","timestamp":1702584128832,"user":{"displayName":"Alireza Vosoughi Rad","userId":"06911821094483688911"},"user_tz":420},"id":"3KiWhYA7UQd7"},"outputs":[],"source":["# maze is a 2d Numpy array of floats between 0.0 to 1.0\n","# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n","# rat = (row, col) initial rat position (defaults to (0,0))\n","\n","class Qmaze(object):\n","    def __init__(self, maze, rat=(0,0)):\n","        self._maze = np.array(maze)\n","        nrows, ncols = self._maze.shape\n","        self.walls = 1 - self._maze\n","        self.target = (nrows-1, ncols-1)   # target cell where the \"cheese\" is\n","        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._maze[r,c] == 1.0]\n","        self.free_cells.remove(self.target)\n","        if self._maze[self.target] == 0.0:\n","            raise Exception(\"Invalid maze: target cell cannot be blocked!\")\n","        if not rat in self.free_cells:\n","            raise Exception(\"Invalid Rat Location: must sit on a free cell\")\n","        self.reset(rat)\n","        self.coverage = np.zeros(self._maze.shape)\n","\n","    def reset(self, rat):\n","        self.rat = rat\n","        self.maze = np.copy(self._maze)\n","        nrows, ncols = self.maze.shape\n","        row, col = rat\n","        self.maze[row, col] = rat_mark\n","        self.state = (row, col, 'start')\n","        self.min_reward = -0.5 * self.maze.size\n","        self.total_reward = 0\n","        self.visited = set()\n","\n","    def update_state(self, action):\n","        nrows, ncols = self.maze.shape\n","        nrow, ncol, nmode = rat_row, rat_col, mode = self.state\n","\n","        if self.maze[rat_row, rat_col] > 0.0:\n","            self.visited.add((rat_row, rat_col))  # mark visited cell\n","\n","        valid_actions = self.valid_actions()\n","\n","        if not valid_actions:\n","            nmode = 'blocked'\n","        elif action in valid_actions:\n","            nmode = 'valid'\n","            if action == LEFT:\n","                ncol -= 1\n","            elif action == UP:\n","                nrow -= 1\n","            if action == RIGHT:\n","                ncol += 1\n","            elif action == DOWN:\n","                nrow += 1\n","        else:                  # invalid action, no change in rat position\n","            mode = 'invalid'\n","\n","        # new state\n","        self.state = (nrow, ncol, nmode)\n","        self.coverage[nrow][ncol] += 1\n","\n","    def get_reward(self):\n","        rat_row, rat_col, mode = self.state\n","        nrows, ncols = self.maze.shape\n","        if rat_row == nrows-1 and rat_col == ncols-1:\n","            return 1.0\n","        if mode == 'blocked':\n","            return 0\n","        if (rat_row, rat_col) in self.visited:\n","            return 0.\n","        if mode == 'invalid':\n","            return 0.\n","        if mode == 'valid':\n","            return 0.\n","\n","    def act(self, action):\n","        self.update_state(action)\n","        reward = self.get_reward()\n","        self.total_reward += reward\n","        status = self.game_status()\n","        envstate = self.observe()\n","        return envstate, reward, status\n","\n","    def observe(self):\n","        canvas = self.draw_env()\n","        canvas = 2 * (self._maze - canvas)\n","        envstate = np.stack([self._maze, self.walls, canvas], axis=0)\n","        return envstate\n","\n","    def draw_env(self):\n","        canvas = np.copy(self.maze)\n","        nrows, ncols = self.maze.shape\n","        # clear all visual marks\n","        for r in range(nrows):\n","            for c in range(ncols):\n","                if canvas[r,c] > 0.0:\n","                    canvas[r,c] = 1.0\n","        # draw the rat\n","        row, col, valid = self.state\n","        canvas[row, col] = rat_mark\n","        return canvas\n","\n","    def game_status(self):\n","        if self.total_reward < self.min_reward:\n","            return 'lose'\n","        rat_row, rat_col, mode = self.state\n","        nrows, ncols = self.maze.shape\n","        if rat_row == nrows-1 and rat_col == ncols-1:\n","            return 'win'\n","\n","        return 'not_over'\n","\n","    def valid_actions(self, cell=None):\n","        if cell is None:\n","            row, col, mode = self.state\n","        else:\n","            row, col = cell\n","        actions = [0, 1, 2, 3]\n","        nrows, ncols = self.maze.shape\n","        if row == 0:\n","            actions.remove(1)\n","        elif row == nrows-1:\n","            actions.remove(3)\n","\n","        if col == 0:\n","            actions.remove(0)\n","        elif col == ncols-1:\n","            actions.remove(2)\n","\n","        if row>0 and self.maze[row-1,col] == 0.0:\n","            actions.remove(1)\n","        if row<nrows-1 and self.maze[row+1,col] == 0.0:\n","            actions.remove(3)\n","\n","        if col>0 and self.maze[row,col-1] == 0.0:\n","            actions.remove(0)\n","        if col<ncols-1 and self.maze[row,col+1] == 0.0:\n","            actions.remove(2)\n","\n","        return actions"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1702584128832,"user":{"displayName":"Alireza Vosoughi Rad","userId":"06911821094483688911"},"user_tz":420},"id":"InpB_5q1Ujjz"},"outputs":[],"source":["from IPython.display import clear_output\n","import time\n","def show(qmaze):\n","    plt.grid('on')\n","    nrows, ncols = qmaze.maze.shape\n","    ax = plt.gca()\n","    ax.set_xticks(np.arange(0.5, nrows, 1))\n","    ax.set_yticks(np.arange(0.5, ncols, 1))\n","    ax.set_xticklabels([])\n","    ax.set_yticklabels([])\n","    canvas = np.copy(qmaze.maze)\n","    for row,col in qmaze.visited:\n","        canvas[row,col] = 0.6\n","    rat_row, rat_col, _ = qmaze.state\n","    canvas[rat_row, rat_col] = 0.3   # rat cell\n","    canvas[nrows-1, ncols-1] = 0.9 # cheese cell\n","    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n","    return img"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1702584128833,"user":{"displayName":"Alireza Vosoughi Rad","userId":"06911821094483688911"},"user_tz":420},"id":"e0zUdS2fUOJl"},"outputs":[],"source":["class NoisyLinear(nn.Module):\n","    \"\"\"Noisy linear module for NoisyNet.\"\"\"\n","    def __init__(self, in_features: int, out_features: int, std_init: float = 0.5):\n","        super(NoisyLinear, self).__init__()\n","\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.std_init = std_init\n","\n","        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.weight_sigma = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.register_buffer(\"weight_epsilon\", torch.Tensor(out_features, in_features))\n","\n","        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n","        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n","        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n","\n","        self.reset_parameters()\n","        self.reset_noise()\n","\n","    def reset_parameters(self):\n","        mu_range = 1 / math.sqrt(self.in_features)\n","        self.weight_mu.data.uniform_(-mu_range, mu_range)\n","        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.in_features))\n","        self.bias_mu.data.uniform_(-mu_range, mu_range)\n","        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.out_features))\n","\n","    def reset_noise(self):\n","        epsilon_in = self.scale_noise(self.in_features)\n","        epsilon_out = self.scale_noise(self.out_features)\n","        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n","        self.bias_epsilon.copy_(epsilon_out)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        return F.linear(\n","            x,\n","            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n","            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n","        )\n","\n","    @staticmethod\n","    def scale_noise(size: int) -> torch.Tensor:\n","        x = torch.randn(size)\n","        return x.sign().mul(x.abs().sqrt())\n","\n","\n","class Network(nn.Module):\n","    def __init__(self, input_size, kernel_size, num_filters, out_features, device=device):\n","        super(Network, self).__init__()\n","        self.net = nn.Sequential(\n","            nn.Conv2d(3, num_filters, kernel_size),\n","            nn.MaxPool2d(2, 2),\n","            nn.Flatten(),\n","            nn.Linear(int(num_filters*(input_size[0]-kernel_size+1)*(input_size[1]-kernel_size+1)/4), 32),\n","            nn.PReLU(),\n","            NoisyLinear(32, out_features)\n","        )\n","        self.to(device)\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","    def act(self, obs):\n","        obs_t = torch.as_tensor(obs, dtype=torch.float32).to(device)\n","        q_values = self.forward(obs_t.unsqueeze(0))\n","        max_q_index = torch.argmax(q_values, dim=1)[0]\n","        action = max_q_index.detach().item()\n","        return action\n","\n","class DQNAgent():\n","    def __init__(self, env, epsilon_start, epsilon_end, epsilon_decay, gamma):\n","        input_size = env.maze.shape\n","        out_features = 4\n","        kernel_size = 3\n","        num_filters = 6\n","        self.num_actions = out_features\n","        self.gamma = gamma\n","        self.targets = None\n","        self.action_qvalues = None\n","        self.online_net = Network(input_size, kernel_size, num_filters, out_features)\n","        self.target_net = Network(input_size, kernel_size, num_filters, out_features)\n","        self.target_net.load_state_dict(self.online_net.state_dict())\n","        self.optimizer = torch.optim.Adam(self.online_net.parameters(), lr=5e-4)\n","        self.epsilon_start = epsilon_start\n","        self.epsilon_end = epsilon_end\n","        self.epsilon_decay = epsilon_decay\n","        self.counter = 1\n","\n","    def choose_action(self, time, obs):\n","        epsilon = np.interp(time, [0, self.epsilon_decay], [self.epsilon_start, self.epsilon_end])\n","        rnd_sample = random.random()\n","        if rnd_sample <= epsilon:\n","            action = random.randrange(self.num_actions)\n","        else:\n","            action = self.online_net.act(obs)\n","\n","        return action\n","\n","    def calculate_target(self, new_obses_t, rews_t, dones_t):\n","        target_qvalues = self.target_net(new_obses_t)\n","        max_target_qvalues = target_qvalues.max(dim=1, keepdim=True)[0]\n","\n","        self.targets = rews_t + self.gamma * (1 - dones_t) * max_target_qvalues\n","\n","    def calculate_action_qvalues(self, obses_t, actions_t):\n","        q_values = self.online_net(obses_t)\n","        self.action_qvalues = torch.gather(input=q_values, dim=1, index=actions_t)\n","\n","    def optimize_network(self):\n","        loss = nn.functional.smooth_l1_loss(self.action_qvalues, self.targets)\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        self.optimizer.step()\n","\n","    def update_target_network(self):\n","        self.target_net.load_state_dict(self.online_net.state_dict())"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1702584128833,"user":{"displayName":"Alireza Vosoughi Rad","userId":"06911821094483688911"},"user_tz":420},"id":"h2ph8rwOUXbN"},"outputs":[],"source":["GAMMA = 0.9\n","BATCH_SIZE = 32\n","BUFFER_SIZE = 100000\n","MIN_REPLAY_SIZE = 1000\n","EPSILON_START = 0.001\n","EPSILON_END = 0.001\n","EPSILON_DECAY = 5000\n","TARGET_UPDATE_FREQ = 200"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"executionInfo":{"elapsed":952,"status":"ok","timestamp":1702584129771,"user":{"displayName":"Alireza Vosoughi Rad","userId":"06911821094483688911"},"user_tz":420},"id":"--h4qZaxXMDH","outputId":"912ca949-76ef-48ee-870b-ef22355d652c"},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x7c8a039d1db0>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYoAAAGKCAYAAAASfgYQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAASUUlEQVR4nO3d0Y7i5vk/8IcklgekoEo9yFKVSr2ASr2Hil4Eh9xI4EY4KxdRrqVHkXIEu4FKsJal+H+wYrL5M/OMJz87s9DPRxpFWN4vb8yLv9g+eAdN0zQBAM/46q0HAMCXTVEAkFIUAKQUBQApRQFASlEAkFIUAKQUBQCpb37rP/z555/jxx9/jG+//TYGg0GXYwKgZ03TxH//+9/405/+FF99lV8z/Oai+PHHH2M6nf7Wfw7AF+CHH36IP//5z+k+v7kovv3224iI+Mc//hHffPObY55UFEXM5/P45z//GUVRdJpd13X8+9//vtnsxWIRHz9+7DT74eEh1uv1zR2TvvNlP59tHt5+9vv37+Ovf/3r47k885vP8JfbTd98803n/wNFUcRoNIrxeNzLgb/l7D5u8w0Gg5s8Jn3ny34+2zy8j+yIaPVZepgNQEpRAJBSFACkFAUAKUUBQEpRAJBSFACkFAUAKUUBQEpRAJBSFACkFAUAKUUBQEpRAJBSFACkFAUAKUUBQEpRAJBSFACkWq+ZXVVVVFX1+Pp4PEZExL/+9a8Yj8edDqqu69hut49runad/fl/by17OBx2nn3JvLVj0ne+7OezzcP7yW5j0DRN02bH5XIZq9Xqavtms4nRaNR+dAC8udPpFPP5PA6Hw4s/9lsXxVNXFNPpNHa7XW9XFLPZLIqikP1Z9mKxiPP53Gn2cDiM9Xp9c8ek73zZz2ebh7efvd/vYzKZtCqK1reeyrKMsiyvthdF0csJQPbTzudz51/Qi1s9Jn3ny75mHt5+9mvyPMwGIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSrdfMrqoqqqp6fH08HiPi0+LfdV13OqhLXte595C92+16W8D91o5J3/myn882D+8nu41B0zRNmx2Xy2WsVqur7ZvNJkajUfvRAfDmTqdTzOfzOBwOMR6P031bF8VTVxTT6TR2u92Lb/Jal18Ws9mst18tsm8/u+982bLvOXu/38dkMmlVFK1vPZVlGWVZXm0viqKXE4Bs2V9KvmzZ95j9mjwPswFIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgFTrNbOrqoqqqh5fH4/HiPi0+Hdd150O6pLXde49ZL979y7O53On2cPhMNbr9c0dk77zZT+fbR7eT3Ybg6ZpmjY7LpfLWK1WV9s3m02MRqP2owPgzZ1Op5jP53E4HGI8Hqf7ti6Kp64optNp7Ha7F9/kteq6ju12G7PZLIqikP1Z9mKx6O2X3K0dk77zZT+fbR7efvZ+v4/JZNKqKFrfeirLMsqyvNpeFEUvJwDZTzufz51/QS9u9Zj0nS/7mnl4+9mvyfMwG4CUogAgpSgASCkKAFKKAoCUogAgpSgASCkKAFKKAoCUogAgpSgASCkKAFKKAoCUogAgpSgASCkKAFKKAoCUogAgpSgASLVeM7uqqqiq6vH18XiMiIjvvvsuBoNBp4O6LLL+7t273hZwr+u609yIeMzsc9zD4bDT3Et2RL/j7iP78/w+P89bnSvm4a+zb/l730f2w8ND630HTdM0bXZcLpexWq2utm82mxiNRu1HB8CbO51OMZ/P43A4xHg8TvdtXRRPXVFMp9N4eHjo7YpisVj01tCz2SyKoug0u67r2G63vY5b9tP5fX6e5sr9ZPssf/Hw8BAfPnxoVRStbz2VZRllWV5t//jx4+tH2NL5fO7l5BIRURRF5xPmos9xy35an5+nuXI/2T7LX7S8RogID7MBeIGiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABItV4zu6qqqKrq8fXxeIyITwt0DwaDTgc1HA5/9d8+suu67jz7ktnnuGU/nd/n52mu3E+2z/IXDw8P8fHjx1b7DpqWK2wvl8tYrVZX2zebTYxGo9eNEIA3dTqdYj6fx+FwiPF4nO7buiieuqKYTqex2+1efJPXqus6ttttzGazKIpC9mfZi8Uizudzp9nD4TDW6/XNHZO+82U/n20e3n72fr+PyWTSqiha33oqyzLKsrzaXhRFLycA2U87n8+df0EvbvWY9J0v+5p5ePvZr8nzMBuAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEi1XjO7qqqoqurx9fF4jIhPi3/Xdd3poC55XefeQ/ZwOOw8+5J5a8ek73zZz2ebh/eT3cagaZqmzY7L5TJWq9XV9s1mE6PRqP3oAHhzp9Mp5vN5HA6HGI/H6b6ti+KpK4rpdBq73e7FN3mtuq5ju93GbDaLoihkf5a9WCzifD53mj0cDmO9Xt/cMek7X/bz2ebh7Wfv9/uYTCatiqL1raeyLKMsy6vtRVH0cgKQ/bTz+dz5F/TiVo9J3/myr5mHt5/9mjwPswFIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgFTrNbOrqoqqqh5fH4/HiPi0+Hdd150O6pLXde49ZA+Hw86zL5m3dkz6zpf9fLZ5eD/ZbQyapmna7LhcLmO1Wl1t32w2MRqN2o8OgDd3Op1iPp/H4XCI8Xic7tu6KJ66ophOp7Hb7V58k9eq6zq2223MZrMoikK27DfJly37nrP3+31MJpNWRdH61lNZllGW5dX2oih6OQHIlv2l5MuWfY/Zr8nzMBuAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEi1XjO7qqqoqurx9fF4jIhPi3/Xdd3poC55XefKvq/svvNly/5fyG5j0DRN02bH5XIZq9Xqavtms4nRaNR+dAC8udPpFPP5PA6HQ4zH43Tf1kXx1BXFdDqN3W734pu8Vl3Xsd1uYzabRVEUsj/LXiwWcT6fO80eDoexXq9v7pj0nS/7+Wzz8Paz9/t9TCaTVkXR+tZTWZZRluXV9qIoejkByH7a+Xzu/At6cavHpO982dfMw9vPfk2eh9kApBQFAClFAUBKUQCQUhQApBQFAClFAUBKUQCQUhQApBQFAClFAUBKUQCQUhQApBQFAClFAUBKUQCQUhQApBQFAClFAUCq9ZrZVVVFVVWPr4/HY0R8Wvy7rutOB3XJ6zr3HrKHw2Hn2ZfMWzsmfefLfj7bPLyf7DYGTdM0bXZcLpexWq2utm82mxiNRu1HB8CbO51OMZ/P43A4xHg8TvdtXRRPXVFMp9PY7XYvvslr1XUd2+02ZrNZFEUh+7PsxWIR5/O50+zhcBjr9frmjknf+bKfzzYPbz97v9/HZDJpVRStbz2VZRllWV5tL4qilxOA7Kedz+fOv6AXt3pM+s6Xfc08vP3s1+R5mA1ASlEAkFIUAKQUBQApRQFASlEAkFIUAKQUBQApRQFASlEAkFIUAKQUBQApRQFASlEAkFIUAKQUBQApRQFASlEAkFIUAKQUBQCpb9ruWFVVVFX1+Pp4PEZExHfffReDwaDTQQ2Hw1iv1/Hu3bvOF3C/ZNd13WluRDxm9jnu4XDYae4lO6LfcfeR/Xl+n5/nrc4V8/DX2bf8ve8j++HhofW+g6ZpmjY7LpfLWK1WV9s3m02MRqP2owPgzZ1Op5jP53E4HGI8Hqf7ti6Kp64optNpPDw89HZFsVgsemvo2WwWRVF0ml3XdWy3217HLfvp/D4/T3PlfrJ9lr94eHiIDx8+tCqK1reeyrKMsiyvtn/8+PH1I2zpfD73cnKJiCiKovMJc9HnuGU/rc/P01y5n2yf5S9aXiNEhIfZALxAUQCQUhQApBQFAClFAUBKUQCQUhQApBQFAClFAUBKUQCQUhQApBQFAClFAUBKUQCQUhQApBQFAClFAUBKUQCQUhQApFqvmV1VVVRV9fj6eDxGRMRut3txYe7XuixWvtvtelsIva7rTnMv2RHR67iHw2GnuRHxmNnnuPvI/jy/z8/zVueKefiLW//e95G93+9jMpm02nfQtFxhe7lcxmq1utq+2WxiNBq9boQAvKnT6RTz+TwOh8OLP/ZbF8VTVxTT6bTXK4rZbNZbQ99q9mKxiPP53Gn2cDiM9Xp9c8ek73zZz2ebh7effbmiaFMUrW89lWUZZVlebS+KopcTgOynnc/nzr+gF7d6TPrOl33NPLz97NfkeZgNQEpRAJBSFACkFAUAKUUBQEpRAJBSFACkFAUAKUUBQEpRAJBSFACkFAUAKUUBQEpRAJBSFACkFAUAKUUBQEpRAJBSFACkWq+ZXVVVVFX1+Pp4PEbEp8W/67rudFCXvK5z7yF7t9v1toD7rR2TvvNlP59tHt5PdhuDpmmaNjsul8tYrVZX2zebTYxGo/ajA+DNnU6nmM/ncTgcYjwep/u2Loqnriim02nsdrsX3+S1Lr8sZrNZb79aZN9+dt/5smXfc/Z+v4/JZNKqKFrfeirLMsqyvNpeFEUvJwDZsr+UfNmy7zH7NXkeZgOQUhQApBQFAClFAUBKUQCQUhQApBQFAClFAUBKUQCQUhQApBQFAClFAUBKUQCQUhQApBQFAClFAUBKUQCQUhQApBQFAKnWa2ZXVRVVVT2+Ph6PEfFp8e+6rjsd1CWv61zZ95Xdd75s2f8L2W0MmqZp2uy4XC5jtVpdbd9sNjEajdqPDoA3dzqdYj6fx+FwiPF4nO7buiieuqKYTqex2+1efJPXqus6ttttzGazKIpC9mfZi8Uizudzp9nD4TDW6/XNHZO+82U/n20e3n72fr+PyWTSqiha33oqyzLKsrzaXhRFLycA2U87n8+df0EvbvWY9J0v+5p5ePvZr8nzMBuAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEi1XjO7qqqoqurx9fF4jIhPi3/Xdd3poC55XefeQ/ZwOOw8+5J5a8ek73zZz2ebh/eT3cagaZqmzY7L5TJWq9XV9s1mE6PRqP3oAHhzp9Mp5vN5HA6HGI/H6b6ti+KpK4rpdBq73e7FN3mtuq5ju93GbDaLoihkf5a9WCzifD53mj0cDmO9Xt/cMek7X/bz2ebh7Wfv9/uYTCatiqL1raeyLKMsy6vtRVH0cgKQ/bTz+dz5F/TiVo9J3/myr5mHt5/9mjwPswFIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgJSiACClKABIKQoAUooCgFTrNbOrqoqqqh5fH4/HiPi0+Hdd150O6pLXde49ZA+Hw86zL5m3dkz6zpf9fLZ5eD/ZbQyapmna7LhcLmO1Wl1t32w2MRqN2o8OgDd3Op1iPp/H4XCI8Xic7tu6KJ66ophOp7Hb7V58k9eq6zq2223MZrMoikL2Z9mLxSLO53On2cPhMNbr9c0dk77zZT+fbR7+vtl///vf4+uvv+40+6effoq//e1vrYqi9a2nsiyjLMur7UVR9HICkP208/nc+Rf04laPSd/5sq+Zh79v9tdff915Ubwmz8NsAFKKAoCUogAgpSgASCkKAFKKAoCUogAgpSgASCkKAFKKAoCUogAgpSgASCkKAFKKAoCUogAgpSgASCkKAFKKAoCUogAg1XrN7Kqqoqqqx9eHwyEiIt6/fx91XXc6qLqu43Q6xX6/72Wx8lvOfnh4iKZpOs1+eHi4yWPSd77s57PNw983+6effup8zezLObzV59i09P333zcR4c+fP3/+7ujvP//5z4vn/0HT8mfB/39F8fPPP8f79+/jj3/8YwwGgzYRrR2Px5hOp/HDDz/EeDyWLftN8mXLvufsw+EQf/nLX+LDhw/xhz/8Id239a2nsiyjLMtfbXsp/P9qPB73cnKRfV/ZfefLln3P2V999fKjag+zAUgpCgBSX2RRlGUZ33///dWtLtmyf8982bJlf9L6YTYA/5u+yCsKAL4cigKAlKIAIKUoAEgpCgBSigKAlKIAIKUoAEj9P2k1l7VvsNPAAAAAAElFTkSuQmCC","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["maze = [\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  1., 1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  1., 1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","]\n","env = Qmaze(maze)\n","show(env)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"IO4xj3gpXtvE"},"outputs":[{"name":"stdout","output_type":"stream","text":["trained 0 times - ep num = 0\n","trained 0 times - ep num = 0\n","trained 0 times - ep num = 0\n","trained 0 times - ep num = 0\n","trained 0 times - ep num = 0\n","trained 0 times - ep num = 0\n","trained 0 times - ep num = 0\n","trained 0 times - ep num = 0\n","trained 0 times - ep num = 0\n","trained 0 times - ep num = 0\n","trained 0 times - ep num = 0\n","trained 0 times - ep num = 1\n","trained 0 times - ep num = 2\n","trained 0 times - ep num = 2\n","trained 0 times - ep num = 3\n","trained 0 times - ep num = 4\n","trained 0 times - ep num = 5\n","trained 0 times - ep num = 6\n","trained 0 times - ep num = 12\n","trained 0 times - ep num = 123\n","trained 0 times - ep num = 288\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n","trained 1 times - ep num = 0\n"]}],"source":["avg_returns = []\n","episodes = []\n","current_coverage = []\n","coverage_steps = [200, 500, 1000, 50000]\n","# prefix = f\"{sigma}_{rate}_\"\n","\n","# Noise defined\n","for k in range(10):\n","    current_return = []\n","\n","    replay_buffer = deque(maxlen=BUFFER_SIZE)\n","    rew_buffer = []\n","    temp_episodes = []\n","\n","    rat_cell = (0, 0)\n","    env = Qmaze(maze)\n","    env.reset(rat_cell)\n","    obs = env.observe()\n","\n","    agent = DQNAgent(env, EPSILON_START, EPSILON_END, EPSILON_DECAY, GAMMA)\n","    cnt = 0\n","    coverage_counter = 0\n","    episode = 0\n","    for step in itertools.count():\n","        agent.counter += 1\n","        action = agent.choose_action(step, obs)\n","\n","        new_obs, rew, done = env.act(action)\n","        Transition = (obs, action, rew, done, new_obs)\n","        replay_buffer.append(Transition)\n","        obs = new_obs\n","\n","\n","        if done != 'not_over':\n","            rat_cell = (0,0)\n","            env.reset(rat_cell)\n","            obs = env.observe()\n","            rew_buffer.append(GAMMA**(cnt))\n","            episode += 1\n","            cnt = 0\n","\n","        if len(replay_buffer) > BATCH_SIZE:\n","            transitions = random.sample(replay_buffer, BATCH_SIZE)\n","            obses = np.asarray([t[0] for t in transitions])\n","            actions = np.asarray([t[1] for t in transitions])\n","            rews = np.asarray([t[2] for t in transitions])\n","            dones = np.asarray([t[3] for t in transitions])\n","            new_obses = np.asarray([t[4] for t in transitions])\n","\n","            converted_dones = [done != 'not_over' for done in dones]\n","\n","            obses_t = torch.as_tensor(obses, dtype=torch.float32).to(device)\n","            actions_t = torch.as_tensor(actions, dtype=torch.int64).unsqueeze(-1).to(device)\n","            rews_t = torch.as_tensor(rews, dtype=torch.float32).unsqueeze(-1).to(device)\n","            dones_t = torch.as_tensor(converted_dones, dtype=torch.float32).unsqueeze(-1).to(device)\n","            new_obses_t = torch.as_tensor(new_obses, dtype=torch.float32).to(device)\n","\n","            # Calculate noise\n","            # var = sigma / np.ceil (agent.counter / rate)\n","            var = 0\n","\n","            agent.calculate_target(new_obses_t, rews_t, dones_t)\n","            agent.calculate_action_qvalues(obses_t, actions_t)\n","            agent.optimize_network()\n","\n","        if step % TARGET_UPDATE_FREQ == 0:\n","            agent.update_target_network()\n","\n","        if step in coverage_steps:\n","            if k == 0:\n","                current_coverage.append(np.copy(env.coverage.reshape(1, env.coverage.shape[0], env.coverage.shape[1])))\n","            else:\n","                current_coverage[coverage_counter] = np.concatenate(\n","                    [current_coverage[coverage_counter], env.coverage.reshape(1, env.coverage.shape[0], env.coverage.shape[1])], axis=0)\n","\n","            coverage_counter += 1\n","\n","        if step > 100000:\n","            episodes.append(np.copy(temp_episodes))\n","            avg_returns.append(np.copy(rew_buffer))\n","            break\n","        cnt += 1\n","\n","        if step % 5000 == 0:\n","            temp_episodes.append(episode)\n","\n","            print(f\"trained {k} times - ep num = {episode}\")\n","\n","min_length = np.min([len(array) for array in avg_returns])\n","np.save(\"episodes.npy\", np.mean(episodes, axis=0))\n","np.save(\"score.npy\", np.mean([array[:min_length] for array in avg_returns], axis=0))\n","for s in range(len(coverage_steps)):\n","    np.save(f\"heat_{coverage_steps[s]}.npy\", np.mean(current_coverage[s], axis=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ethe5oOkYsJo"},"outputs":[],"source":["plt.plot(rew_buffer)\n","plt.show()\n","plt.imshow(np.mean(current_coverage[1], axis=0)[2:][:], cmap='hot', interpolation='nearest')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XHk9eEpxKgi1"},"outputs":[],"source":["env.reset((0, 0))\n","done = 'not_over'\n","while done == 'not_over':\n","    action = agent.choose_action(step, obs)\n","\n","    new_obs, rew, done = env.act(action)\n","\n","    step += 1\n","    obs = new_obs\n","    plt.figure()\n","    show(env)\n","print(step)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dg9fCmxDcweZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}
